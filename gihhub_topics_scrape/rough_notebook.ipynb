{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a03a76b",
   "metadata": {},
   "source": [
    "# Top Repository on github"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af2c7db",
   "metadata": {},
   "source": [
    "## Pick a website and describe your objective\n",
    "\n",
    "- Browse through different sites and pick on to scrape. Check the \"Project Ideas\" section for inspiration.\n",
    "- Identify the information you'd like to scrape from the site. Decide the format of the output CSV file.\n",
    "- Summarize your project idea and outline your strategy in a Juptyer notebook. Use the \"New\" button above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b586db",
   "metadata": {},
   "source": [
    "Here are the steps we'll follow:\n",
    "\n",
    "- We're going to scrape https://github.com/topics\n",
    "- We'll get a list of topics. For each topic, we'll get topic title, topic page URL and topic description\n",
    "- For each topic, we'll get the top 25 repositories in the topic from the topic page\n",
    "- For each repository, we'll grab the repo name, username, stars and repo URL\n",
    "- For each topic we'll create a CSV file in the following format:\n",
    "\n",
    "```\n",
    "Repo Name,Username,Stars,Repo URL\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5db9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install requests --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db3e516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130e5a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_url= 'https://github.com/topics'\n",
    "response= requests.get(topics_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a554b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "response= requests.get(topics_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01bed1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.status_code \n",
    "## 200 means a goood response code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ca9c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d370e4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_contents = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9671dc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('webpage.html' , 'w' ,encoding=\"utf-8\") as f:\n",
    "    f.write(page_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76695e47",
   "metadata": {},
   "source": [
    " ## Use Beautiful Soup to parse and extract the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7634bd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install beautifulsoup4 --upgrade --quiet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7619704",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f10c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = BeautifulSoup(page_contents, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76331a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758cbaa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4755c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_class = 'f3 lh-condensed mb-0 mt-1 Link--primary'\n",
    "topics_titles = doc.find_all('p' , {\"class\":select_class})\n",
    "len(topics_titles)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ac3e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b640c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99de2c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_class_desc = 'f5 color-text-secondary mb-0 mt-1'\n",
    "topics_desc = doc.find_all('p' , {\"class\":select_class_desc})\n",
    "len(topics_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa83015",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_desc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a16019a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58983f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "## topics_titles , topics_desc\n",
    "select_url = 'd-flex no-underline'\n",
    "topics_url = doc.find_all('a' , {\"class\":select_url})\n",
    "len(topics_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4899ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_url[0]['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d2c08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_url2= \"https://github.com\" + topics_url[2]['href']\n",
    "print(topic_url2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638897a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b12c741",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_titles_list= []\n",
    "\n",
    "for i in topics_titles:\n",
    "    topics_titles_list.append(i.text)\n",
    "    \n",
    "print(topics_titles_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1b2207",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_desc_list= []\n",
    "\n",
    "for i in topics_desc:\n",
    "    topics_desc_list.append(i.text.strip())\n",
    "    \n",
    "    \n",
    "for i in topics_desc_list:\n",
    "    print(\"*--> \" + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24da9039",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_url_list= []\n",
    "base_url =\"https://github.com\"\n",
    "for i in topics_url:\n",
    "    topics_url_list.append(base_url + i['href'])\n",
    "    \n",
    "for i in topics_url_list:\n",
    "    print(\"*--> \" + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a4ac77",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9fea3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f444f2",
   "metadata": {},
   "source": [
    "### Lists with us \n",
    "- topics_titles_list\n",
    "- topics_desc_list\n",
    "- topics_url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05117b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {\n",
    "    'Titles': topics_titles_list, \n",
    "    'Description': topics_desc_list, \n",
    "    'URL': topics_url_list\n",
    "} \n",
    "    \n",
    "topics_df = pd.DataFrame(dict)\n",
    "\n",
    "topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f879ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13c214b",
   "metadata": {},
   "source": [
    "## Create a CSV file put of a dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a45709",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_df.to_csv('topics.csv' , index =None  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870200b5",
   "metadata": {},
   "source": [
    "## Getting information out of topic page "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b0ee63",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_url2 =topics_url_list[0]\n",
    "topics_url2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4155e45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response2= requests.get(topics_url2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cc13ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "response2.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1711d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(response2.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab2d27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_doc = BeautifulSoup(response2.text, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32397eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(topic_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38006556",
   "metadata": {},
   "source": [
    "- in this we want the <b>Username repository name and star count</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46314536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a parent class which has username class and repository name in it \n",
    "parent_class = 'f3 color-text-secondary text-normal lh-condensed'\n",
    "parent = topic_doc.find_all('h3' , parent_class) \n",
    "len(parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de860d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117d2b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_tags = parent[0].find_all('a')\n",
    "a_tags[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5358996a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_tags[1].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb65d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_tags[1]['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca97c10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "star_class = 'social-count float-none'\n",
    "star_count = topic_doc.find_all('a' , {'class': star_class}) \n",
    "len(star_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f283fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "star_count[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718674e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_star(stars_str):\n",
    "    if(stars_str[-1] == 'k'):\n",
    "        return int(float(stars_str[:-1])*1000)\n",
    "    return int(stars_str)\n",
    "\n",
    "print(parse_star(star_count[0].text.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be1ebc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repo_info(parent , star_tag):\n",
    "    # this will return all the required info \n",
    "    a_tags = a_tags = parent.find_all('a')\n",
    "    username = a_tags[0].text.strip()\n",
    "    repo_name = a_tags[1].text.strip()\n",
    "    repo_url = base_url + a_tags[1]['href']\n",
    "    stars = parse_star(star_tag.text.strip())\n",
    "    \n",
    "    return username, repo_name , repo_url ,stars "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b80a4f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cdcb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_repo_info ={\n",
    "    'username':[],\n",
    "    'repo_name':[],\n",
    "    'stars':[],\n",
    "    'repo_url':[]\n",
    "}\n",
    "for i in range(len(parent)):\n",
    "    repo_info = get_repo_info(parent[i], star_count[i])\n",
    "    topic_repo_info['username'].append(repo_info[0])\n",
    "    topic_repo_info['repo_name'].append(repo_info[1])\n",
    "    topic_repo_info['repo_url'].append(repo_info[2])\n",
    "    topic_repo_info['stars'].append(repo_info[3])\n",
    "    \n",
    "topic_repo_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153c02ad",
   "metadata": {},
   "source": [
    "## We are doing this for only one topic we need to do this for all the topics  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c8b575",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_repo_df  = pd.DataFrame(topic_repo_info)\n",
    "topics_repo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87fe5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_star(stars_str):\n",
    "    if(stars_str[-1] == 'k'):\n",
    "        return int(float(stars_str[:-1])*1000)\n",
    "    return int(stars_str)\n",
    "\n",
    "\n",
    "\n",
    "def get_repo_info(parent , star_tag):\n",
    "    # this will return all the required info \n",
    "    a_tags = parent.find_all('a')\n",
    "    username = a_tags[0].text.strip()\n",
    "    repo_name = a_tags[1].text.strip()\n",
    "    repo_url = base_url + a_tags[1]['href']\n",
    "    stars = parse_star(star_tag.text.strip())\n",
    "    \n",
    "    return username, repo_name , repo_url ,stars \n",
    "\n",
    "\n",
    "\n",
    "def get_repo_all(topics_url):\n",
    "    response= requests.get(topics_url)\n",
    "    if(response.status_code!= 200):\n",
    "        raise Exception(\"Failed to load page\")\n",
    "    topic_doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    parent_class = 'f3 color-text-secondary text-normal lh-condensed'\n",
    "    parent = topic_doc.find_all('h3' , {'class':parent_class}) \n",
    "    \n",
    "    star_class = 'social-count float-none'\n",
    "    star_count = topic_doc.find_all('a' , {'class': star_class}) \n",
    "    \n",
    "    topic_repo_info ={\n",
    "    'username':[],\n",
    "    'repo_name':[],\n",
    "    'stars':[],\n",
    "    'repo_url':[]\n",
    "    }\n",
    "    \n",
    "    for i in range(len(parent)):\n",
    "        repo_info = get_repo_info(parent[i], star_count[i])\n",
    "        topic_repo_info['username'].append(repo_info[0])\n",
    "        topic_repo_info['repo_name'].append(repo_info[1])\n",
    "        topic_repo_info['repo_url'].append(repo_info[2])\n",
    "        topic_repo_info['stars'].append(repo_info[3])\n",
    "        \n",
    "        \n",
    "    return pd.DataFrame(topic_repo_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfa0918",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_url_list[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d70a012",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_repo_all(topics_url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1484a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_titles(doc):\n",
    "    topics_titles_list= []\n",
    "    \n",
    "    select_class = 'f3 lh-condensed mb-0 mt-1 Link--primary'\n",
    "    topics_titles = doc.find_all('p' , {\"class\":select_class})\n",
    "    \n",
    "    for i in topics_titles:\n",
    "        topics_titles_list.append(i.text)\n",
    "    return topics_titles_list\n",
    "\n",
    "\n",
    "def get_desc(doc):\n",
    "    topics_desc_list= []\n",
    "    \n",
    "    select_class_desc = 'f5 color-text-secondary mb-0 mt-1'\n",
    "    topics_desc = doc.find_all('p' , {\"class\":select_class_desc})\n",
    "    for i in topics_desc:\n",
    "        topics_desc_list.append(i.text.strip())\n",
    "    return topics_desc_list\n",
    "\n",
    "\n",
    "def get_url(doc):\n",
    "    select_url = 'd-flex no-underline'\n",
    "    topics_url = doc.find_all('a' , {\"class\":select_url})\n",
    "\n",
    "    topics_url_list= []\n",
    "    base_url =\"https://github.com\"\n",
    "    \n",
    "    for i in topics_url:\n",
    "        topics_url_list.append(base_url + i['href'])\n",
    "    \n",
    "    return topics_url_list\n",
    "    \n",
    "\n",
    "def scrape_topics():\n",
    "    topics_url= 'https://github.com/topics'\n",
    "    response= requests.get(topics_url)\n",
    "    if(response.status_code!= 200):\n",
    "        raise Exception(\"Failed to load page\")\n",
    "        \n",
    "    doc = BeautifulSoup(response.text , 'html.parser')   \n",
    "    \n",
    "    topics_dict = {\n",
    "    \"titles\" : get_titles(doc),\n",
    "    \"description\": get_desc(doc),\n",
    "    \"url\" : get_url(doc),\n",
    "    } \n",
    "    \n",
    "    return pd.DataFrame(topics_dict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9862086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install os --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9b572f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scarpe_topic and scrape_topics are two different functions \n",
    "import os\n",
    "def scrape_topic(topic_url , path): \n",
    "    if os.path.exists(path):\n",
    "        print(\"skippping a file here ---------\")\n",
    "        return\n",
    "    \n",
    "    topic_df = get_repo_all(topic_url)\n",
    "    topic_df.to_csv(path, index= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef2ac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_df =scrape_topics()\n",
    "topics_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e3eecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topics_repos():\n",
    "    print(\"List of top topics from Github \")\n",
    "    topics_df =scrape_topics()\n",
    "    \n",
    "    os.makedirs('data', exist_ok = True)\n",
    "    \n",
    "    for index, row in topics_df.iterrows():\n",
    "        print('Scraping top repositories for \"{}\"'.format(row['titles']))\n",
    "        scrape_topic(row[\"url\"], \"data/\"+ row[\"titles\"]+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598b90c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_topics_repos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3460233",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
